{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Of Contents <a id=\"index\"></a>\n",
    "\n",
    "\n",
    "- [Dataset managing](#dataset)  \n",
    "- [District Data](#district-data)\n",
    "- [Data Exploration](#data-exploration)\n",
    "- [Matrix](#matrix)\n",
    "  \n",
    "\n",
    "#### Models\n",
    "- [**Decision Tree**](#decision-tree)\n",
    "    - [**Parameter Tunning**](#parameter-tunning)\n",
    "- [**K-Nearest Neighbor**](#k-nearest-neighbor)\n",
    "    - [**Parameter Tunning**](#parameter-tunning-2)  \n",
    "- [**Support-Vector Machines**](#support-vector-machines)\n",
    "    - [**Parameter Tunning**](#parameter-tunning-3)\n",
    "- [**Neural Networks**](#neural-networks)\n",
    "    - [**Parameter Tunning**](#parameter-tunning-4)\n",
    "- [**Logistic Regression**](#logistic-regression)\n",
    "    - [**Parameter Tunning**](#parameter-tunning-5)\n",
    "- [**Naive Bayes**](#naive-bayes)\n",
    "    - [**Parameter Tunning**](#parameter-tunning-6)\n",
    "- [**Random Forest**](#random-forest)\n",
    "    - [**Parameter Tunning**](#parameter-tunning-7)\n",
    "- [**XGBoost**](#xgboost)\n",
    "    - [**Parameter Tunning**](#parameter-tunning-8)\n",
    "- [**MLP**](#mlp)\n",
    "    - [**Parameter Tunning**](#parameter-tunning-9)\n",
    "- [**Ada Boost**](#ada-boost)\n",
    "    - [**Parameter Tunning**](#parameter-tunning-10)\n",
    "- [**Voting**](#voting)\n",
    "\n",
    "#### [Apply Model](#apply-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graphs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(x, missing = \"\"):\n",
    "    return pd.read_csv('Dataset/' + x + '.csv', sep = ';', low_memory = False, na_values = missing_values).rename(str.strip, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_min(x):\n",
    "    return x.abs().min()\n",
    "abs_min.__name__ = 'abs_min'\n",
    "\n",
    "def rangev(x):\n",
    "    return x.max() - x.min()\n",
    "rangev.__name__ = 'range'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decade(year):\n",
    "    year_int = int(year)\n",
    "    string = str(year_int//10) + \"0-\" + str(year_int//10) + \"9\"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month(year):\n",
    "    string = year[2:4] + \"/\" + year[0:2]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balance(year):\n",
    "    year_int = int(float(year))\n",
    "    string = \"1\" + \"0\"*(len(str(year_int))-1) + \"-\" + \"9\" + \"9\"*(len(str(year_int))-1)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAge(birthDate, loanDate):\n",
    "    loan = list(map(int,loanDate.split(\"-\")))\n",
    "    birth = list(map(int,birthDate.split(\"-\")))\n",
    "\n",
    "    loan_date = date(loan[0], loan[1], loan[2])\n",
    "    \n",
    "\n",
    "    birth_date = date(birth[0], birth[1], birth[2])\n",
    "    return (int((loan_date-birth_date).days/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_credit_cash(val):\n",
    "    return sum(val==\"credit in cash\")\n",
    "def count_collect(val):\n",
    "    return sum(val==\"collection from another bank\")\n",
    "def count_with_cash(val):\n",
    "    return sum(val==\"withdrawal in cash\")\n",
    "def count_remi(val):\n",
    "    return sum(val==\"remittance to another bank\")\n",
    "def count_with_card(val):\n",
    "    return sum(val==\"credit card withdrawal\")\n",
    "def count_interest(val):\n",
    "    return sum(val==\"interest credited\")\n",
    "\n",
    "def count_withdrawal(val):\n",
    "    return sum(val==\"withdrawal\")\n",
    "def count_credit(val):\n",
    "    return sum(val==\"credit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for getting the mean of the operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_credit_cash(val):\n",
    "    return np.mean(val==\"credit in cash\")\n",
    "def mean_collect(val):\n",
    "    return np.mean(val==\"collection from another bank\")\n",
    "def mean_with_cash(val):\n",
    "    return np.mean(val==\"withdrawal in cash\")\n",
    "def mean_remi(val):\n",
    "    return np.mean(val==\"remittance to another bank\")\n",
    "def mean_with_card(val):\n",
    "    return np.mean(val==\"credit card withdrawal\")\n",
    "def mean_interest(val):\n",
    "    return np.mean(val==\"interest credited\")\n",
    "\n",
    "def mean_withdrawal(val):\n",
    "    return np.mean(val==\"withdrawal\")\n",
    "def mean_credit(val):\n",
    "    return np.mean(val==\"credit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for getting the standard deviation of the operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_credit_cash(val):\n",
    "    return np.std(val==\"credit in cash\")\n",
    "def std_collect(val):\n",
    "    return np.std(val==\"collection from another bank\")\n",
    "def std_with_cash(val):\n",
    "    return np.std(val==\"withdrawal in cash\")\n",
    "def std_remi(val):\n",
    "    return np.std(val==\"remittance to another bank\")\n",
    "def std_with_card(val):\n",
    "    return np.std(val==\"credit card withdrawal\")\n",
    "def std_interest(val):\n",
    "    return np.std(val==\"interest credited\")\n",
    "\n",
    "\n",
    "def std_withdrawal(val):\n",
    "    return np.std(val==\"withdrawal\")\n",
    "def std_credit(val):\n",
    "    return np.std(val==\"credit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for getting the covariance of the operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_credit_cash(val):\n",
    "    return np.cov(val==\"credit in cash\")\n",
    "def cov_collect(val):\n",
    "    return np.cov(val==\"collection from another bank\")\n",
    "def cov_with_cash(val):\n",
    "    return np.cov(val==\"withdrawal in cash\")\n",
    "def cov_remi(val):\n",
    "    return np.cov(val==\"remittance to another bank\")\n",
    "def cov_with_card(val):\n",
    "    return np.cov(val==\"credit card withdrawal\")\n",
    "def cov_interest(val):\n",
    "    return np.cov(val==\"interest credited\")\n",
    "\n",
    "def cov_withdrawal(val):\n",
    "    return np.cov(val==\"withdrawal\")\n",
    "def cov_credit(val):\n",
    "    return np.cov(val==\"credit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to merge the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset(loan, district, client, card, trans, account, disp):\n",
    "\n",
    "    df = loan\n",
    "    df = pd.merge(df, trans, on = 'account_id', suffixes = ('', '_trans'))\n",
    "    df = pd.merge(df, account, on = 'account_id', suffixes = ('', '_account'))\n",
    "    \n",
    "    df = pd.merge(df, district.set_index('code'), left_on = 'district_id', right_index = True, suffixes = ('', '_district'))\n",
    "    df = pd.merge(df, disp, on = 'account_id', suffixes = ('', '_disp'))\n",
    "    df = pd.merge(df, card, on = 'disp_id', how = 'outer', suffixes = ('', '_card'))\n",
    "    df = pd.merge(df, client, on = 'client_id', suffixes = ('', '_client'))\n",
    "    df = df.drop(['district_id_client'], axis=1)\n",
    "    df.info()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to parse the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dates(df, date_var, birth):\n",
    "    loan_dates = [str(int(x))[:2] + \"-\" + str(int(x))[2:4] + \"-\" + str(int(x))[4:] for x in df[date_var]]\n",
    "    return [calculateAge(df[birth][n],loan_dates[n]) for n in range(0,len(df[birth]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to parse date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_ranges(df,age):\n",
    "    age_loan_train = df[age].astype(str)\n",
    "    return [get_decade(age_loan_train[n]) for n in range(0, len(df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to parse the client birth and genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_client(client_data):\n",
    "    birth_dates = client_data['birth_number']\n",
    "    dates_parsed = []\n",
    "    genre = []\n",
    "    for bdate in birth_dates:\n",
    "        month = int(str(bdate)[2:4])\n",
    "        if month > 12:\n",
    "            genre.append(0)\n",
    "            month = month - 50\n",
    "            if month < 10:\n",
    "                month = '0' + str(month)\n",
    "            else:\n",
    "                month = str(month)\n",
    "        else:\n",
    "            if month < 10:\n",
    "                month = '0' + str(month)\n",
    "            else:\n",
    "                month = str(month)\n",
    "            genre.append(1)\n",
    "        dates_parsed.append(str(bdate)[:2] + '-' + month + '-' + str(bdate)[4:])\n",
    "        \n",
    "    return dates_parsed, genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_aggr_dataset(loan, district, client, card, trans, account, disp):\n",
    "    # build aggregate dataset\n",
    "\n",
    "    columns = trans.columns.values.tolist()\n",
    "    columns.remove(\"trans_id\")\n",
    "    columns.remove(\"amount\")\n",
    "    columns.remove(\"balance\")\n",
    "    columns.remove(\"operation\")\n",
    "    columns.remove(\"type\")\n",
    "    \n",
    "    trans=trans.groupby(columns, as_index=False,group_keys=False).agg({\n",
    "        \"operation\": [\"count\",count_credit_cash, count_collect, count_with_cash, count_remi, count_with_card, count_interest, \n",
    "                     mean_credit_cash, mean_collect, mean_with_cash, mean_remi, mean_with_card, mean_interest,\n",
    "                     std_credit_cash, std_collect, std_with_cash, std_remi, std_with_card, std_interest,\n",
    "                     cov_credit_cash, cov_collect, cov_with_cash, cov_remi, cov_with_card, cov_interest], \n",
    "        \"amount\": [\"mean\",\"min\",\"max\",\"std\",\"last\",abs_min,rangev],\n",
    "        \"balance\": [\"mean\",\"min\",\"max\",\"std\",\"last\",abs_min,rangev],\n",
    "        \"type\": [count_withdrawal, count_credit, mean_withdrawal, mean_credit, std_withdrawal, std_credit,cov_withdrawal, cov_credit]\n",
    "    })\n",
    "    trans.columns = ['%s%s' % (a, '_%s' % b if b else '') for a, b in trans.columns]\n",
    "    \n",
    "    df = loan\n",
    "    df = pd.merge(df, trans, on = 'account_id', suffixes = ('', '_trans'))\n",
    "    df = pd.merge(df, account, on = 'account_id', suffixes = ('', '_account'))\n",
    "    df = pd.merge(df, district.set_index('code'), left_on = 'district_id', right_index = True, suffixes = ('', '_district'))\n",
    "    df = pd.merge(df, disp, on = 'account_id', suffixes = ('', '_disp'))\n",
    "    df = pd.merge(df, card, on = 'disp_id', how = 'outer', suffixes = ('', '_card'))\n",
    "    df = pd.merge(df, client, on = 'client_id', suffixes = ('', '_client'))\n",
    "    df = df.drop(['district_id_client'], axis=1)\n",
    "\n",
    "\n",
    "#     df[\"age_loan\"]=parse_dates(df,\"date\",\"birth_number\")\n",
    "#     df[\"age_account\"]=parse_dates(df,\"date_account\",\"birth_number\")\n",
    "    \n",
    "#     df[\"age_loan_range\"] = parse_date_ranges(df,\"age_loan\")\n",
    "#     df[\"age_account_range\"] = parse_date_ranges(df,\"age_account\")\n",
    "#     df.drop(['date', 'date_account', 'birth_number'], axis=1, inplace=True)\n",
    "#     df.drop(['card_id', 'type', 'issued'], axis=1, inplace=True)\n",
    "    \n",
    "#     df.drop(['disp_id', 'client_id'], axis=1, inplace=True)\n",
    "\n",
    "    df.info()\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = ['?', 'NA', '']\n",
    "account_data = dataset('account', missing_values)\n",
    "client_data = dataset('client', missing_values)\n",
    "disp_data = dataset('disp', missing_values)\n",
    "district_data = dataset('district', missing_values)\n",
    "card_train = dataset('card_train', missing_values)\n",
    "card_test = dataset('card_test')\n",
    "loan_train = dataset('loan_train', missing_values)\n",
    "loan_test = dataset('loan_test')\n",
    "trans_train = dataset('trans_train', missing_values)\n",
    "trans_test = dataset('trans_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    plt.figure(figsize=(15,8))\n",
    "    sb.countplot(x='region', data=district_data)\n",
    "    plt.title(\"Number of districts per region\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.xlabel('Region');\n",
    "    plt.ylabel('Number of districts from region');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To study if the region might have an impact on the acceptance of the loan we will create a graph comparing the percentages of successful loans per region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    district_data_region = district_data.copy()\n",
    "    region_data = loan_train\n",
    "    region_data = pd.merge(region_data, trans_train, on = 'account_id', suffixes = ('', '_trans'))\n",
    "    region_data = pd.merge(region_data, account_data, on = 'account_id', suffixes = ('', '_account'))\n",
    "    #train_data = train_data.dropna()\n",
    "    region_data = pd.merge(region_data, district_data_region.set_index('code'), left_on = 'district_id', right_index = True, suffixes = ('', '_district'))\n",
    "\n",
    "    region_total = region_data[\"region\"].value_counts()\n",
    "    tuples_total = [tuple((x, y)) for x, y in region_total.items()]\n",
    "\n",
    "    regions_status_1 = region_data.loc[region_data['status'] == 1]\n",
    "    region_total_1 = regions_status_1[\"region\"].value_counts()\n",
    "    tuples_total_1 = [tuple((x, y)) for x, y in region_total_1.items()]\n",
    "\n",
    "    lista=[]\n",
    "    for x in tuples_total:\n",
    "        for y in tuples_total_1:\n",
    "            if x[0]==y[0]:\n",
    "                lista.append((x[0],x[1],y[1]))\n",
    "\n",
    "    percentages = [(i[0],i[2] / i[1]) for i in lista]\n",
    "    percentages.sort(key = lambda x: -x[1])\n",
    "\n",
    "    x = [i[0] for i in percentages]\n",
    "    y = [i[1] for i in percentages]\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    sb.barplot(x,y)\n",
    "    plt.ylim(0.7, 1)\n",
    "    plt.title(\"Percentage of successful loans per region\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.xlabel('Region');\n",
    "    plt.ylabel('Percentage of successful loans');\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *name* and the *region* of a **district** is not relevant to our analysis, as the *code* parameter is enough to identify a district. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing name and region from district\n",
    "district_data.drop(['name', 'region'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the different values the parameter type can have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    disp_data_pie = disp_data.copy()\n",
    "\n",
    "    ser = disp_data_pie.groupby('type')['type'].count()\n",
    "    ser = ser.sort_values(ascending=False)\n",
    "    ser = ser.iloc[[0,1]]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.pie(ser.values, labels=ser.index, startangle=90, autopct=lambda x:int(x/100.*ser.sum()+0.1), pctdistance=0.8, counterclock=False)\n",
    "    ax.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.title('Type of disposition', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    fig.set_size_inches(15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since only owner can issue permanent orders and ask for a loan, there is no interess in keeping this parameter in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only owner can issue permanent orders and ask for a loan\n",
    "disp_owners = disp_data[disp_data.type.eq('OWNER')]\n",
    "disp_owners.drop(['type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As *birth_number* column doesn't add any value to our model as it is in the original data (it's represented as an int in format YYMMDD for men and YYMM+50DD for women), let's put it in format YY-MM-DD and create a new column called *genre*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data[\"birth_number\"], client_data[\"genre\"] = parse_client(client_data)\n",
    "client_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the *genre* distribution, where 1 means male and 0 female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    client_data_genre_copy = client_data.copy()\n",
    "\n",
    "    ser = client_data_genre_copy.groupby('genre')['genre'].count()\n",
    "    ser = ser.sort_values(ascending=False)\n",
    "    ser = ser.iloc[[0,1]]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.pie(ser.values, labels=[\"Male\",\"Female\"], startangle=90, autopct=lambda x:int(x/100.*ser.sum()+0.1), pctdistance=0.8, counterclock=False)\n",
    "    ax.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.title('Genre distribution', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    fig.set_size_inches(15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back](#index)\n",
    "#### Transactions Data <a id=\"transactions-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at null values distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    # Null values for each attribute\n",
    "    trans_train.isnull().sum().plot(kind='bar', figsize=(18,8), fontsize=14,);\n",
    "    plt.title(\"Number of null variables per collumn\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.ylabel('Null values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trans_train.operation.value_counts())\n",
    "print('Null values: ' + str(trans_train.operation.isnull().sum()))\n",
    "print()\n",
    "print(trans_train.k_symbol.value_counts())\n",
    "print('Null values: ' + str(trans_train.k_symbol.isnull().sum()))\n",
    "print()\n",
    "print(trans_train.type.value_counts())\n",
    "print('Null values: ' + str(trans_train.type.isnull().sum()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    trans_data_copy = trans_train.copy()\n",
    "    trans_data_copy = trans_data_copy.loc[:, trans_data_copy.columns.intersection(['type','operation'])]\n",
    "    trans_data_copy[\"operation\"] = trans_data_copy[\"operation\"].fillna('NaN')\n",
    "    trans_data_copy.sort_values(\"operation\")\n",
    "    sb.displot(trans_data_copy,x='operation', y='type', aspect=3)\n",
    "    plt.xlabel('Operation');\n",
    "    plt.ylabel('Type');\n",
    "    plt.title(\"Comparition between Operation and Type\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all the rows with operation *credit in cash* and *collection from another bank* are of type credit. All the *withdrawal in cash*, *remittance to another bank* and *credit cash withdrawal* operations are of the type *withdraw* or *withdrawal with cash* (in the case of the homonymous operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for **type** column, let's convert all *withdrawal in cash* occurrences into *withdrawal*, as it is basically the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_train.loc[trans_train['type'] == \"withdrawal in cash\", 'type'] = \"withdrawal\"\n",
    "trans_test.loc[trans_test['type'] == \"withdrawal in cash\", 'type'] = \"withdrawal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    trans_data_copy = trans_train.copy()\n",
    "    trans_data_copy = trans_data_copy.groupby(['k_symbol', 'operation'])['operation'].count()\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "    trans_data_copy.plot(kind='bar', stacked=True)\n",
    "    plt.xlabel('K_symbol');\n",
    "    plt.ylabel('Quantity');\n",
    "    plt.title(\"Number of operation types per k_symbol\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    trans_data_copy = trans_train.copy()\n",
    "    trans_data_copy[\"operation\"]=trans_data_copy[\"operation\"].fillna(\"Not Available\")\n",
    "    trans_data_copy[\"k_symbol\"]=trans_data_copy[\"k_symbol\"].fillna(\"Not Available\")\n",
    "    trans_data_copy['k_symbol'] = trans_data_copy['k_symbol'].replace([' '],['Not Available'])\n",
    "    trans_data_copy['operation'] = trans_data_copy['operation'].replace([''],['Not Available'])\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    sb.catplot(x=\"operation\", hue=\"k_symbol\", kind=\"count\",\n",
    "                palette=\"pastel\", edgecolor=\".6\",\n",
    "                data=trans_data_copy, height=10, aspect=1.5)\n",
    "    plt.title('Relation between k_symbols and operation', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.ylim(0)\n",
    "    plt.rcParams['figure.figsize']=(20,10)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the great majority of the k_symbol types are directly related to a certain operation type.\n",
    "All rows that have **operation** column with null value have *interested credited* in *k_symbol* column. We can try to replace the null values of *operation* column with the value that is in *k_symbol* column and then delete *k_symbol* parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_train.loc[trans_train['operation'].isna(), 'operation'] = trans_train.loc[trans_train['operation'].isna(), 'k_symbol']\n",
    "trans_test.loc[trans_test['operation'].isna(), 'operation'] = trans_test.loc[trans_test['operation'].isna(), 'k_symbol']\n",
    "\n",
    "trans_train.drop(['k_symbol'], axis=1, inplace=True)\n",
    "trans_test.drop(['k_symbol'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As follows we can see the months when the most transfers were taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    trans_data_copy = trans_train.copy()\n",
    "    trans_data_copy = trans_data_copy.sort_values('date')\n",
    "    trans_data_copy = trans_data_copy.astype({'date': str})\n",
    "\n",
    "    trans_data_copy['date'] = trans_data_copy['date'].apply(lambda x: get_month(x[0:4]))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(25,20))\n",
    "    plt.title(\"Months with the most tranfers\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    ax = sb.countplot(x=\"date\", data=trans_data_copy)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove *bank* and *account* columns, as these columns only record the destination account and have too many null values. *date* column is not relevant to our analysis too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_train.drop(['bank', 'account', 'date'], axis=1, inplace=True)\n",
    "trans_test.drop(['bank', 'account', 'date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back](#index)\n",
    "#### District Data <a id=\"district-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at null values distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    # Null values for each attribute\n",
    "    district_data.isnull().sum().plot(kind='bar', figsize=(18,8), fontsize=14,);\n",
    "    plt.title(\"Number of null variables per collumn\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.ylabel('Null values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    district_scatter_plot = sb.PairGrid(district_data)\n",
    "    district_scatter_plot.map(plt.scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*unemploymant rate in '95* and *no. of commited crimes '95* have a null value each. Let's look at the distribution of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title('Distribution of district\\'s unemploymant rate in \\'95', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.hist(district_data['unemploymant rate \\'95'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title('Distribution of district\\'s no. of commited crimes \\'95', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.hist(district_data['no. of commited crimes \\'95'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill null values in in district's *unemploymant rate in '95* and *district's no. of commited crimes '95* with median and mean values of the column, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_data['unemploymant rate \\'95'].fillna(district_data['unemploymant rate \\'95'].median(), inplace=True)\n",
    "\n",
    "district_data['no. of commited crimes \\'95'].fillna(district_data['no. of commited crimes \\'95'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back](#index)\n",
    "#### Card Data <a id=\"card-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at null values distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    # Null values for each attribute\n",
    "    district_data.isnull().sum().plot(kind='bar', figsize=(18,8), fontsize=14,);\n",
    "    plt.title(\"Number of null variables per collumn\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.ylabel('Null values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    card_data_copy = card_train.copy()\n",
    "\n",
    "    ser = card_data_copy.groupby('type')['type'].count()\n",
    "    ser = ser.sort_values(ascending=False)\n",
    "    ser = ser.iloc[[0,1,2]]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.pie(ser.values, labels=ser.index, startangle=90, autopct=lambda x:int(x/100.*ser.sum()+0.1), pctdistance=0.8, counterclock=False)\n",
    "    ax.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.title('Card Type distribution', y=1.05, fontsize=20)\n",
    "    fig.set_size_inches(15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back](#index)\n",
    "#### Dataset Managing <a id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_train_aggr, district_data_train_aggr, client_data_train_aggr, card_train_aggr, trans_train_aggr, account_data_train_aggr, disp_data_train_aggr = loan_train.copy(), district_data.copy(), client_data.copy(), card_train.copy(), trans_train.copy(), account_data.copy(), disp_owners.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_test_aggr, district_data_test_aggr, client_data_test_aggr, card_test_aggr, trans_test_aggr, account_data_test_aggr, disp_data_test_aggr = loan_test.copy(), district_data.copy(), client_data.copy(), card_test.copy(), trans_test.copy(), account_data.copy(), disp_owners.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the merge and aggregate function for both the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = merge_aggr_dataset(loan_train_aggr, district_data_train_aggr, client_data_train_aggr, card_train_aggr, trans_train_aggr, account_data_train_aggr, disp_data_train_aggr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = merge_aggr_dataset(loan_test_aggr, district_data_test_aggr, client_data_test_aggr, card_test_aggr, trans_test_aggr, account_data_test_aggr, disp_data_test_aggr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a column *age_loan* where we will keep the age of the client at the time of the requested loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"age_loan\"] = parse_dates(train_data, \"date\", \"birth_number\")\n",
    "test_data[\"age_loan\"] = parse_dates(test_data, \"date\", \"birth_number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's create a new column that represents the age of each client when he creates the account (*age_account*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"age_account\"] = parse_dates(train_data, \"date_account\", \"birth_number\")\n",
    "test_data[\"age_account\"] = parse_dates(test_data, \"date_account\", \"birth_number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's simplify *age_loan* and *age_account* values, converting them into age ranges divided by decades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"age_loan_range\"] = parse_date_ranges(train_data, \"age_loan\")\n",
    "test_data[\"age_loan_range\"] = parse_date_ranges(test_data, \"age_loan\")\n",
    "\n",
    "train_data[\"age_account_range\"] = parse_date_ranges(train_data, \"age_account\")\n",
    "test_data[\"age_account_range\"] = parse_date_ranges(test_data, \"age_account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_copy = train_data.copy()\n",
    "\n",
    "    train_data_copy = train_data_copy.astype({'age_loan': str})\n",
    "\n",
    "    train_data_copy['age_loan'] = train_data_copy['age_loan'].apply(lambda x: get_decade(x))\n",
    "\n",
    "    train_data_copy = train_data_copy.sort_values('age_loan')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.title(\"Age by decade at the date of the loan\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    ax = sb.countplot(x=\"age_loan\", data=train_data_copy)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the months when the accounts were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_copy = train_data.copy()\n",
    "    train_data_copy = train_data_copy.sort_values('date_account')\n",
    "    train_data_copy = train_data_copy.astype({'date_account': str})\n",
    "\n",
    "    train_data_copy['date_account'] = train_data_copy['date_account'].apply(lambda x: get_month(x[0:4]))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(25,20))\n",
    "    plt.title(\"Date of creation of the account per month\")\n",
    "    ax = sb.countplot(x=\"date_account\", data=train_data_copy)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the month and year of when the loans were created and their relation to the number of successful loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_copy = train_data.copy()\n",
    "    train_data_copy = train_data_copy.sort_values('date')\n",
    "    train_data_copy = train_data_copy.astype({'date': str})\n",
    "\n",
    "    train_data_copy['date'] = train_data_copy['date'].apply(lambda x: get_month(x[0:4]))\n",
    "\n",
    "    train_data_copy = train_data_copy.astype({'status': str})\n",
    "    train_data_copy['status'] = train_data_copy['status'].replace(['1.0','-1.0'],['Successful Loan','Unsuccessful Loan'])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(25,20))\n",
    "    plt.title(\"Number of successful loans per month\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    ax = sb.countplot(x ='date', hue = \"status\", data = train_data_copy)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have taken all informations that we need from all dates, we can remove these columns from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['date', 'date_account', 'birth_number', 'age_loan', 'age_account'], axis=1, inplace=True)\n",
    "test_data.drop(['date', 'date_account', 'birth_number', 'age_loan', 'age_account'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*issued* and *type* columns have too many null values, so we can remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['issued', 'type'], axis=1, inplace=True)\n",
    "test_data.drop(['issued', 'type'], axis=1, inplace=True)\n",
    "train_data_no_dummies = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = 1\n",
    "\n",
    "if option == 0:\n",
    "    train_data.drop(['operation_count_credit_cash', 'operation_count_collect', 'operation_count_with_cash', 'operation_count_remi', 'operation_count_with_card', 'operation_count_interest', 'operation_mean_credit_cash', 'operation_mean_collect', 'operation_mean_with_cash', 'operation_mean_remi', 'operation_mean_with_card', 'operation_mean_interest', 'operation_std_credit_cash', 'operation_std_collect', 'operation_std_with_cash', 'operation_std_remi', 'operation_std_with_card', 'operation_std_interest', 'operation_cov_credit_cash', 'operation_cov_collect', 'operation_cov_with_cash', 'operation_cov_remi', 'operation_cov_with_card', 'operation_cov_interest', 'balance_std', 'balance_last', 'type_count_withdrawal', 'type_count_credit', 'type_mean_withdrawal', 'type_mean_credit', 'type_std_withdrawal', 'type_std_credit', 'type_cov_withdrawal', 'type_cov_credit'], axis=1, inplace=True)\n",
    "    test_data.drop(['operation_count_credit_cash', 'operation_count_collect', 'operation_count_with_cash', 'operation_count_remi', 'operation_count_with_card', 'operation_count_interest', 'operation_mean_credit_cash', 'operation_mean_collect', 'operation_mean_with_cash', 'operation_mean_remi', 'operation_mean_with_card', 'operation_mean_interest', 'operation_std_credit_cash', 'operation_std_collect', 'operation_std_with_cash', 'operation_std_remi', 'operation_std_with_card', 'operation_std_interest', 'operation_cov_credit_cash', 'operation_cov_collect', 'operation_cov_with_cash', 'operation_cov_remi', 'operation_cov_with_card', 'operation_cov_interest', 'balance_std', 'balance_last', 'type_count_withdrawal', 'type_count_credit', 'type_mean_withdrawal', 'type_mean_credit', 'type_std_withdrawal', 'type_std_credit', 'type_cov_withdrawal', 'type_cov_credit'], axis=1, inplace=True)  \n",
    "if option == 1:\n",
    "    train_data.drop(['age_account_range', 'operation_count_credit_cash', 'operation_count_collect', 'operation_count_with_cash', 'operation_count_remi', 'operation_count_with_card', 'operation_count_interest', 'operation_mean_credit_cash', 'operation_mean_collect', 'operation_mean_with_cash', 'operation_mean_remi', 'operation_mean_with_card', 'operation_mean_interest', 'operation_std_credit_cash', 'operation_std_collect', 'operation_std_with_cash', 'operation_std_remi', 'operation_std_with_card', 'operation_std_interest', 'operation_cov_credit_cash', 'operation_cov_collect', 'operation_cov_with_cash', 'operation_cov_remi', 'operation_cov_with_card', 'operation_cov_interest', 'balance_std', 'balance_last', 'type_std_withdrawal', 'type_std_credit', 'type_cov_withdrawal', 'type_cov_credit', 'amount_std', 'amount_last', 'amount_range', 'balance_std', 'balance_last', 'balance_range'], axis=1, inplace=True)\n",
    "    test_data.drop(['age_account_range', 'operation_count_credit_cash', 'operation_count_collect', 'operation_count_with_cash', 'operation_count_remi', 'operation_count_with_card', 'operation_count_interest', 'operation_mean_credit_cash', 'operation_mean_collect', 'operation_mean_with_cash', 'operation_mean_remi', 'operation_mean_with_card', 'operation_mean_interest', 'operation_std_credit_cash', 'operation_std_collect', 'operation_std_with_cash', 'operation_std_remi', 'operation_std_with_card', 'operation_std_interest', 'operation_cov_credit_cash', 'operation_cov_collect', 'operation_cov_with_cash', 'operation_cov_remi', 'operation_cov_with_card', 'operation_cov_interest', 'balance_std', 'balance_last', 'type_std_withdrawal', 'type_std_credit', 'type_cov_withdrawal', 'type_cov_credit', 'amount_std', 'amount_last', 'amount_range', 'balance_std', 'balance_last', 'balance_range'], axis=1, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data, columns=['frequency'], dtype=bool)\n",
    "test_data = pd.get_dummies(test_data, columns=['frequency'], dtype=bool)\n",
    "    \n",
    "train_data = pd.get_dummies(train_data, columns=['age_loan_range'], dtype = bool)\n",
    "test_data = pd.get_dummies(test_data, columns=['age_loan_range'], dtype = bool)\n",
    "\n",
    "if option != 1:\n",
    "    train_data = pd.get_dummies(train_data, columns=['age_account_range'], dtype = bool)\n",
    "    test_data = pd.get_dummies(test_data, columns=['age_account_range'], dtype = bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_inputs = test_data.drop(columns=[\"loan_id\", \"status\"])\n",
    "# test_data = test_data.drop(columns=[\"status\"])\n",
    "all_ids_comp = test_data['loan_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "#### Data Exploration <a class=\"anchor\" id=\"data-exploration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    ax = sb.barplot(train_data[\"duration\"], train_data[\"amount\"])\n",
    "    plt.xlabel('Duration');\n",
    "    plt.ylabel('Amount');\n",
    "    plt.title('Loan duration compared the amount', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that with bigger loan amounts the time taken to repay them is exponentially higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "    ax = plt.plot(train_data[\"amount\"], train_data[\"payments\"], linestyle='none', marker='o', alpha=0.3)\n",
    "    plt.title('Number of payments per different amount', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.xlabel('Amount');\n",
    "    plt.ylabel('Payments');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can check by the values in the graph, it seems that the number of payments is defined by the bank since the results are very linear and follow a line according to the amount loaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    #ax = sb.barplot(train_data[\"amount_trans\"], train_data[\"balance\"])\n",
    "    plt.plot(train_data[\"balance_mean\"],train_data[\"amount_mean\"], 'o', color='green');\n",
    "    plt.title('Distribution of tranfer amount by balance', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.ylabel('Transfer Amount');\n",
    "    plt.xlabel('Balance');\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see as the balance increases the transfer amount also increase and is rarely higher than the balance. It can also be seen that a straight continous line exists with gradient 1. This means the amount of some transfers are actually correspondent, or close, to the total amount in the account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_copy = train_data.copy()\n",
    "    train_data_copy = train_data_copy.astype({'status': str})\n",
    "    train_data_copy['status'] = train_data_copy['status'].replace(['1.0','-1.0'],['Successful Loan','Unsuccessful Loan'])\n",
    "\n",
    "    train_data_copy = train_data_copy.groupby(['no. of cities', 'status'])['status'].count().unstack().fillna(0)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "    train_data_copy.plot(kind='bar', stacked=True)\n",
    "    plt.title(\"Number of cities per district and loan success rate\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_copy = train_data.copy()\n",
    "\n",
    "    train_data_copy = train_data_copy.astype({'status': str})\n",
    "    train_data_copy['status'] = train_data_copy['status'].replace(['1.0','-1.0'],['Successful Loan','Unsuccessful Loan'])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    sb.violinplot(y=train_data_copy[\"no. of inhabitants\"], x=train_data_copy[\"status\"])\n",
    "    plt.title('Influence of number of inhabitants in loan success', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.ylim(0)\n",
    "    fig.set_size_inches(15, 15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_copy = train_data.copy()\n",
    "\n",
    "    train_data_copy = train_data.copy()\n",
    "    train_data_copy = train_data_copy.astype({'age_loan': str})\n",
    "\n",
    "    train_data_copy['age_loan'] = train_data_copy['age_loan'].apply(lambda x: get_decade(x))\n",
    "\n",
    "    train_data_copy = train_data_copy.astype({'status': str})\n",
    "    train_data_copy['status'] = train_data_copy['status'].replace(['1.0','-1.0'],['Successful Loan','Unsuccessful Loan'])\n",
    "\n",
    "    train_data_copy = train_data_copy.groupby(['age_loan', 'status'])['status'].count().unstack().fillna(0)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "    train_data_copy.plot(kind='bar', stacked=True)\n",
    "    plt.title(\"Loan success rate per decade of age\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_copy = train_data.copy()\n",
    "\n",
    "    train_data_copy = train_data_copy.astype({'status': str})\n",
    "    train_data_copy['status'] = train_data_copy['status'].replace(['1.0','-1.0'],['Successful Loan','Unsuccessful Loan'])\n",
    "\n",
    "    train_data_copy = train_data_copy.groupby(['genre', 'status'])['status'].count().unstack().fillna(0)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "    train_data_copy.plot(kind='bar', stacked=True)\n",
    "    plt.title(\"Loan success rate per decade of genre\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    train_data_names = train_data.copy()\n",
    "    train_data_names[\"genre\"] = train_data_names[\"genre\"].astype(str)\n",
    "    train_data_names[\"genre\"].replace({\"1\": \"Male\" , \"0\": \"Female\"}, inplace=True)\n",
    "\n",
    "    sb.scatterplot(train_data_names[\"amount\"],train_data_names[\"age_loan\"],train_data_names[\"genre\"], alpha=0.5, sizes=(10, 1000), hue=\"time\")\n",
    "    plt.xlabel(\"Amount\")\n",
    "    plt.ylabel(\"Age\")\n",
    "    plt.title(\"Amount by age and genre\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_names = train_data.copy()\n",
    "\n",
    "    train_data_names = train_data_names.astype({'age_loan': str})\n",
    "\n",
    "    train_data_names['age_loan'] = train_data_names['age_loan'].apply(lambda x: get_decade(x))\n",
    "\n",
    "    train_data_names = train_data_names.sort_values('age_loan')\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    sb.boxplot(x=train_data_names[\"age_loan\"], y=train_data_names[\"amount\"])\n",
    "    plt.title(\"Loan amount by age\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_ages = train_data_no_dummies.copy()\n",
    "\n",
    "    train_data_ages = train_data_ages.astype({'age_loan': str})\n",
    "\n",
    "    train_data_ages['age_loan'] = train_data_ages['age_loan'].apply(lambda x: get_decade(x))\n",
    "\n",
    "    train_data_ages = train_data_ages.astype({'age_account': str})\n",
    "\n",
    "    train_data_ages['age_account'] = train_data_ages['age_account'].apply(lambda x: get_decade(x))\n",
    "\n",
    "    train_data_names = train_data_ages.sort_values('age_loan')\n",
    "    sb.barplot(x='age_account', y='amount', hue='age_loan', data=train_data_ages, saturation=0.8)\n",
    "    plt.title(\"Date of creation of account compared to amount and age when the loan was made\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_ages = train_data_no_dummies.copy()\n",
    "\n",
    "    train_data_ages = train_data_ages.astype({'age_loan': str})\n",
    "\n",
    "    train_data_ages['age_loan'] = train_data_ages['age_loan'].apply(lambda x: get_decade(x))\n",
    "\n",
    "    train_data_balance = train_data_ages.astype({'balance_mean': str})\n",
    "\n",
    "    train_data_balance['balance'] = train_data_balance['balance_mean'].apply(lambda x: get_balance(x))\n",
    "\n",
    "    train_data_balance = train_data_balance.sort_values('balance_mean')\n",
    "    sb.boxplot(x='balance', y='amount', hue='age_loan', data=train_data_balance, saturation=0.8)\n",
    "    plt.title(\"Balance and amount of loan by age\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    train_data_names = train_data.copy()\n",
    "    train_data_names[\"genre\"] = train_data_names[\"genre\"].astype(str)\n",
    "    train_data_names[\"genre\"].replace({\"1\": \"Male\" , \"0\": \"Female\"}, inplace=True)\n",
    "\n",
    "    sb.scatterplot(train_data_names[\"average salary\"],train_data_names[\"age_loan\"],train_data_names[\"district_id\"], alpha=0.5, sizes=(10, 1000), hue=\"time\")\n",
    "    plt.xlabel(\"Average Salary\")\n",
    "    plt.ylabel(\"Age\")\n",
    "    plt.title(\"Average Salary by age and district\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As follows we can see the average salary by age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_copy = train_data.copy()\n",
    "    train_data_copy = train_data_copy.astype({'age_loan': str})\n",
    "\n",
    "    train_data_copy['age_loan'] = train_data_copy['age_loan'].apply(lambda x: get_decade(x))\n",
    "\n",
    "    train_data_copy = train_data_copy.sort_values('age_loan')\n",
    "    train_data_copy[\"average salary\"] = train_data_copy[\"average salary\"].astype(float)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    sb.boxplot(x=train_data_copy[\"age_loan\"], y=train_data_copy[\"average salary\"])\n",
    "    plt.xlabel('age_loan', y=1.05, fontsize=15, labelpad=15)\n",
    "    plt.ylabel('average salary', x=0.7, fontsize=15, labelpad=15)\n",
    "    plt.title('Average salary per decade of age', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    fig.set_size_inches(15, 10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_copy = train_data.copy()\n",
    "    train_data_copy[\"genre\"] = train_data_copy[\"genre\"].astype(str)\n",
    "    train_data_copy[\"genre\"].replace({\"0\": \"Female\",\"1\": \"Male\"}, inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.ylim(9000, 10000)\n",
    "    sb.barplot(x = train_data_copy[\"genre\"], y = train_data_copy[\"average salary\"])\n",
    "    plt.title(\"Average Salary by genre\", fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    # display\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back](#index)\n",
    "#### Matrix <a id=\"matrix\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping ids\n",
    "#train_data_no_ids = train_data.drop(['loan_id', 'account_id', 'district_id', 'disp_id', 'client_id', 'card_id', 'trans_id'], axis=1)\n",
    "#train_data_no_ids = train_data.drop(['client_id', 'account_id', 'district_id', 'disp_id', 'card_id', 'trans_id', 'age_loan', 'age_account'], axis=1)\n",
    "#test_data_no_ids = test_data.drop(['client_id', 'account_id', 'district_id', 'disp_id', 'card_id', 'trans_id', 'age_loan', 'age_account'], axis=1)\n",
    "train_data_no_ids = train_data.drop(['account_id', 'district_id', 'disp_id', 'client_id', 'card_id'], axis=1)\n",
    "test_data_no_ids = test_data.drop(['account_id', 'district_id', 'disp_id', 'client_id', 'card_id'], axis=1)\n",
    "\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = train_data_no_ids.corr().abs()\n",
    "if show_graphs:\n",
    "    plt.figure(figsize = (20,6))\n",
    "    sb.heatmap(corr_matrix, annot=True)\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# Drop features \n",
    "train_data_no_ids.drop(to_drop, axis=1, inplace=True)\n",
    "test_data_no_ids.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "print(\"{} Dropped columns: {}\".format(len(to_drop), to_drop) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_no_ids.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = train_data_no_ids[train_data_no_ids.columns.drop(['loan_id', 'status'])]\n",
    "all_labels = train_data_no_ids['status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a test dataset with 25% of the credit_data_subset\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(all_inputs, all_labels, test_size=0.25, random_state=1)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion = True\n",
    "run_param_tunning = True\n",
    "run_classifiers = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## Classifiers <a class=\"anchor\" id=\"classifiers\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_classifiers:\n",
    "    model = 5\n",
    "\n",
    "    if model == 0:\n",
    "        classifier = DecisionTreeClassifier()\n",
    "    elif model == 1:\n",
    "        classifier = KNeighborsClassifier()\n",
    "    elif model == 2:\n",
    "        classifier = SVC(probability=True)\n",
    "    elif model == 3:\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit only to the training data\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        # Now apply the transformations to the data:\n",
    "        X_train_nn = scaler.transform(X_train)\n",
    "        X_test_nn = scaler.transform(X_test)\n",
    "\n",
    "        # Create the classifier\n",
    "        classifier = MLPClassifier(random_state=1, max_iter=500) \n",
    "    elif model == 4:\n",
    "        classifier = LogisticRegression()\n",
    "    elif model == 5:\n",
    "        classifier = GaussianNB()\n",
    "    elif model == 6:\n",
    "        classifier = RandomForestClassifier(300)\n",
    "    elif model == 7:\n",
    "        classifier = XGBClassifier()\n",
    "    elif model == 8:\n",
    "        classifier = MLPClassifier(alpha=1, max_iter=1000)\n",
    "    elif model == 9:\n",
    "        classifier = AdaBoostClassifier()\n",
    "    elif model == 10:\n",
    "        classifier = VotingClassifier(\n",
    "        estimators=[('dt', DecisionTreeClassifier()), ('svm', LinearSVC()), ('xgb', XGBClassifier())],\n",
    "        voting='hard', weights=[1,1,1]\n",
    "    )\n",
    "        \n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier_prediction = classifier.predict(X_test)\n",
    "\n",
    "    classifier_classification_report = classification_report(y_test, classifier_prediction, output_dict=True)\n",
    "\n",
    "    print(f\"Classification report:\\n{classification_report(y_test, classifier_prediction)}\\n\")\n",
    "\n",
    "    sb.set(font_scale=1.0)\n",
    "    \n",
    "    ax = plt.subplot()\n",
    "\n",
    "    confusion_matrix_dtc = confusion_matrix(y_test, classifier_prediction)\n",
    "\n",
    "    sb.heatmap(confusion_matrix_dtc, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## Decision Tree <a class=\"anchor\" id=\"decision-tree\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Feature Selection\n",
    "decision_tree_classifier = RFECV(decision_tree_classifier, scoring='roc_auc')\n",
    "\n",
    "# Train the classifier on the training set\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = decision_tree_classifier.predict(X_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print()\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_dt = confusion_matrix(y_train, predictions_train)\n",
    "sb.heatmap(confusion_matrix_dt, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = decision_tree_classifier.predict(X_test) \n",
    "dtc_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "f1_dt = f1_score(y_test, predictions_test)\n",
    "roc_dt = roc_auc_score(y_test, predictions_test)\n",
    "print(\"F1 Score: {}\".format(f1_dt))\n",
    "print(f\"ROC: {roc_dt}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_dt = confusion_matrix(y_test, predictions_test)\n",
    "sb.heatmap(confusion_matrix_dt, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning <a class=\"anchor\" id=\"parameter-tunning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    parameter_grid = {'criterion': ['gini', 'entropy'],\n",
    "                    'splitter': ['best', 'random'],\n",
    "                    'max_depth': range(1, 10),\n",
    "                    'max_features': range(10,20)}\n",
    "\n",
    "    # grid_search = GridSearchCV(DecisionTreeClassifier(),\n",
    "    #                            param_grid=parameter_grid,\n",
    "    #                            cv=10,\n",
    "    #                            verbose=4,\n",
    "    #                            n_jobs=-1)\n",
    "\n",
    "    dt_classifier = DecisionTreeClassifier(min_samples_leaf = 10)\n",
    "\n",
    "    dt_grid_search = GridSearchCV(dt_classifier, scoring=\"precision_weighted\", cv=10, param_grid=parameter_grid)\n",
    "    dt_grid_search.fit(X_train, y_train)\n",
    "    print('Best score: {}'.format(dt_grid_search.best_score_))\n",
    "\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TRAIN\")\n",
    "    predictions_train = dt_grid_search.predict(X_train)\n",
    "    print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "    print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_dt = confusion_matrix(y_train, predictions_train)\n",
    "    sb.heatmap(confusion_matrix_dt, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TEST\")\n",
    "    predictions_test = dt_grid_search.predict(X_test) \n",
    "    dtc_tun_classification_report = classification_report(y_test, predictions_test, target_names=['not pay', 'pay'])\n",
    "    f1_dt_tun = f1_score(y_test, predictions_test)\n",
    "    roc_f1_dt = roc_auc_score(y_test, predictions_test)\n",
    "    print(\"F1 Score: {}\".format(f1_dt_tun))\n",
    "    print(f\"ROC: {roc_f1_dt}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_dt = confusion_matrix(y_test, predictions_test)\n",
    "    sb.heatmap(confusion_matrix_dt, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## K-Nearest Neighbor <a class=\"anchor\" id=\"k-nearest-neighbor\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Feature Selection\n",
    "# knn = RFECV(knn, scoring='roc_auc')\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = knn.predict(X_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print()\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_knn = confusion_matrix(y_train, predictions_train)\n",
    "sb.heatmap(confusion_matrix_knn, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = knn.predict(X_test) \n",
    "knn_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "f1_knn = f1_score(y_test, predictions_test)\n",
    "roc_knn = roc_auc_score(y_test, predictions_test)\n",
    "print(\"F1 Score: {}\".format(f1_knn))\n",
    "print(f\"ROC: {roc_knn}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_knn = confusion_matrix(y_test, predictions_test)\n",
    "sb.heatmap(confusion_matrix_knn, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning <a class=\"anchor\" id=\"parameter-tunning-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    # parameter_grid = {'n_neighbors': [5,10,15,20],\n",
    "    #                   'weights': ['uniform', 'distance'],\n",
    "    #                   'algorithm': ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "    # grid_search = GridSearchCV(KNeighborsClassifier(),\n",
    "    #                            param_grid=parameter_grid,\n",
    "    #                            scoring='precision_weighted',\n",
    "    #                            cv=10,\n",
    "    #                            n_jobs=3,\n",
    "    #                            verbose=4)\n",
    "\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "    parameter_grid = {'n_neighbors': [3,5,11,19],\n",
    "                    'weights': ['uniform','distance'],\n",
    "                    'p':[1,2],\n",
    "                    'algorithm':['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "    knn_grid_search = GridSearchCV(knn_classifier, parameter_grid, scoring=\"roc_auc\", n_jobs=-1, cv=10)\n",
    "    knn_grid_search.fit(X_train, y_train)\n",
    "    print('Best score: {}'.format(knn_grid_search.best_score_))\n",
    "\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TRAIN\")\n",
    "    predictions_train = knn_grid_search.predict(X_train)\n",
    "    print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "    print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_knn = confusion_matrix(y_train, predictions_train)\n",
    "    sb.heatmap(confusion_matrix_knn, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TEST\")\n",
    "    predictions_test = knn_grid_search.predict(X_test) \n",
    "    knn_tun_classification_report = classification_report(y_test, predictions_test, target_names=['not pay', 'pay'])\n",
    "    f1_knn_tun = f1_score(y_test, predictions_test)\n",
    "    roc_knn_tun = roc_auc_score(y_test, predictions_test)\n",
    "    print(\"F1 Score: {}\".format(f1_knn_tun))\n",
    "    print(f\"ROC: {roc_knn_tun}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_knn = confusion_matrix(y_test, predictions_test)\n",
    "    sb.heatmap(confusion_matrix_knn, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## Support-Vector Machines <a class=\"anchor\" id=\"support-vector-machines\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability=True)\n",
    "\n",
    "# Feature Selection\n",
    "# svc = RFECV(svc, scoring='roc_auc')\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = svc.predict(X_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print()\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_svc = confusion_matrix(y_train, predictions_train)\n",
    "sb.heatmap(confusion_matrix_svc, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = svc.predict(X_test) \n",
    "svm_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "f1_svm = f1_score(y_test, predictions_test)\n",
    "roc_svm = roc_auc_score(y_test, predictions_test)\n",
    "print(\"F1 Score: {}\".format(f1_svm))\n",
    "print(f\"ROC: {roc_svm}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_svc = confusion_matrix(y_test, predictions_test)\n",
    "sb.heatmap(confusion_matrix_svc, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning <a class=\"anchor\" id=\"parameter-tunning-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    svm_classifier = SVC(probability=True)\n",
    "\n",
    "    parameter_grid = {'kernel': ['linear','rbf','poly']}\n",
    "\n",
    "    svm_grid_search = GridSearchCV(svm_classifier, scoring=\"roc_auc\", cv=5, param_grid=parameter_grid)\n",
    "    svm_grid_search.fit(X_train, y_train)\n",
    "    print('Best score: {}'.format(svm_grid_search.best_score_))\n",
    "\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TRAIN\")\n",
    "    predictions_train = svm_grid_search.predict(X_train)\n",
    "    print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "    print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_svm = confusion_matrix(y_train, predictions_train)\n",
    "    sb.heatmap(confusion_matrix_svm, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TEST\")\n",
    "    predictions_test = svm_grid_search.predict(X_test) \n",
    "    svm_tun_classification_report = classification_report(y_test, predictions_test, target_names=['not pay', 'pay'])\n",
    "    f1_svm_tun = f1_score(y_test, predictions_test)\n",
    "    roc_svm_tun = roc_auc_score(y_test, predictions_test)\n",
    "    print(\"F1 Score: {}\".format(f1_svm_tun))\n",
    "    print(f\"ROC: {roc_svm_tun}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_svm = confusion_matrix(y_test, predictions_test)\n",
    "    sb.heatmap(confusion_matrix_svm, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## Neural Networks <a class=\"anchor\" id=\"neural-networks\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Feature Selection\n",
    "#scaler = RFECV(scaler, scoring='roc_auc')\n",
    "\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_train_nn = scaler.transform(X_train)\n",
    "X_test_nn = scaler.transform(X_test)\n",
    "\n",
    "# Create the classifier\n",
    "ANNClassifier = MLPClassifier(random_state=1, max_iter=500)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "ANNClassifier.fit(X_train_nn, y_train)\n",
    "\n",
    "predictions_test = ANNClassifier.predict(X_test_nn)\n",
    "\n",
    "f1_nn = f1_score(y_test, predictions_test)\n",
    "roc_nn = roc_auc_score(y_test, predictions_test)\n",
    "print(\"F1 Score: {}\".format(f1_nn))\n",
    "print(f\"ROC: {roc_nn}\")\n",
    "\n",
    "confusion_matrix_ann = confusion_matrix(y_test,predictions_test)\n",
    "\n",
    "nn_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "print(classification_report(y_test,predictions_test))\n",
    "\n",
    "sb.set(font_scale=1.0)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "sb.heatmap(confusion_matrix_ann, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()\n",
    "\n",
    "best_nn_classification_report = nn_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning <a class=\"anchor\" id=\"parameter-tunning-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    parameter_grid = {'activation': ['tanh','identity','logistic','relu'],\n",
    "                    'solver': ['adam','lbfgs','sgd'],\n",
    "                    'hidden_layer_sizes': [3,5,8,13,21,34],\n",
    "                    'verbose': [True]}\n",
    "\n",
    "    cross_validation = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    grid_search = GridSearchCV(ANNClassifier,\n",
    "                            param_grid=parameter_grid,\n",
    "                            cv=cross_validation)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print('Best score: {}'.format(grid_search.best_score_))\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    print('Best estimator: {}'.format(grid_search.best_estimator_))\n",
    "    ANNClassifier = grid_search.best_estimator_\n",
    "    yk_pred = ANNClassifier.predict(X_test)\n",
    "\n",
    "    best_nn_classification_report = classification_report(y_test, yk_pred, output_dict=True)\n",
    "\n",
    "    print(\"--- Improved model ---\\n\")\n",
    "    print(f\"Classification report:\\n{best_nn_classification_report}\\n\")\n",
    "\n",
    "    sb.set(font_scale=1.0)\n",
    "\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    confusion_matrix_ann = confusion_matrix(y_test, yk_pred)\n",
    "    \n",
    "    f1_nn_tun = f1_score(y_test, predictions_test)\n",
    "    roc_nn_tun = roc_auc_score(y_test, predictions_test)\n",
    "    print(\"F1 Score: {}\".format(f1_nn_tun))\n",
    "    print(f\"ROC: {roc_nn_tun}\")\n",
    "\n",
    "    sb.heatmap(confusion_matrix_ann, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## Logistic Regression <a class=\"anchor\" id=\"logistic-regression\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "# Feature Selection\n",
    "lr = RFECV(lr, scoring='roc_auc')\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = lr.predict(X_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print()\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_lr = confusion_matrix(y_train, predictions_train)\n",
    "sb.heatmap(confusion_matrix_lr, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = lr.predict(X_test) \n",
    "lr_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "f1_lr = f1_score(y_test, predictions_test)\n",
    "roc_lr = roc_auc_score(y_test, predictions_test)\n",
    "print(\"F1 Score: {}\".format(f1_lr))\n",
    "print(f\"ROC: {roc_lr}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_lr = confusion_matrix(y_test, predictions_test)\n",
    "sb.heatmap(confusion_matrix_lr, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning <a class=\"anchor\" id=\"parameter-tunning-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    lr_classifier = LogisticRegression()\n",
    "\n",
    "    lr_grid_search = GridSearchCV(lr_classifier, scoring=\"roc_auc\", cv=5, param_grid={})\n",
    "    lr_grid_search.fit(X_train, y_train)\n",
    "    print('Best score: {}'.format(lr_grid_search.best_score_))\n",
    "\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TRAIN\")\n",
    "    predictions_train = lr_grid_search.predict(X_train)\n",
    "    print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "    print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_lr = confusion_matrix(y_train, predictions_train)\n",
    "    sb.heatmap(confusion_matrix_lr, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TEST\")\n",
    "    predictions_test = lr_grid_search.predict(X_test) \n",
    "    lr_tun_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "    f1_lr_tun = f1_score(y_test, predictions_test)\n",
    "    roc_lr_tun = roc_auc_score(y_test, predictions_test)\n",
    "    print(\"F1 Score: {}\".format(f1_lr_tun))\n",
    "    print(f\"ROC: {roc_lr_tun}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_lr = confusion_matrix(y_test, predictions_test)\n",
    "    sb.heatmap(confusion_matrix_lr, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## Naive Bayes <a class=\"anchor\" id=\"naive-bayes\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "# Feature Selection\n",
    "# nb = RFECV(nb, scoring='roc_auc')\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = nb.predict(X_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print()\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_nb = confusion_matrix(y_train, predictions_train)\n",
    "sb.heatmap(confusion_matrix_nb, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = nb.predict(X_test) \n",
    "nb_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "f1_nb = f1_score(y_test, predictions_test)\n",
    "roc_nb = roc_auc_score(y_test, predictions_test)\n",
    "print(\"F1 Score: {}\".format(f1_nb))\n",
    "print(f\"ROC: {roc_nb}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_nb = confusion_matrix(y_test, predictions_test)\n",
    "sb.heatmap(confusion_matrix_nb, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning <a class=\"anchor\" id=\"parameter-tunning-6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    nb_classifier = GaussianNB()\n",
    "\n",
    "    nb_grid_search = GridSearchCV(nb_classifier, scoring=\"roc_auc\", cv=5, param_grid={})\n",
    "    nb_grid_search.fit(X_train, y_train)\n",
    "    print('Best score: {}'.format(nb_grid_search.best_score_))\n",
    "\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TRAIN\")\n",
    "    predictions_train = nb_grid_search.predict(X_train)\n",
    "    print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "    print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_nb = confusion_matrix(y_train, predictions_train)\n",
    "    sb.heatmap(confusion_matrix_nb, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TEST\")\n",
    "    predictions_test = nb_grid_search.predict(X_test) \n",
    "    nb_tun_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "    f1_nb_tun = f1_score(y_test, predictions_test)\n",
    "    roc_nb_tun = roc_auc_score(y_test, predictions_test)\n",
    "    print(\"F1 Score: {}\".format(f1_nb_tun))\n",
    "    print(f\"ROC: {roc_nb_tun}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_nb = confusion_matrix(y_test, predictions_test)\n",
    "    sb.heatmap(confusion_matrix_nb, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## Random Forest <a class=\"anchor\" id=\"random-forest\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Feature Selection\n",
    "rf = RFECV(rf, scoring='roc_auc')\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = rf.predict(X_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print()\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_rf = confusion_matrix(y_train, predictions_train)\n",
    "sb.heatmap(confusion_matrix_rf, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = rf.predict(X_test)\n",
    "rf_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "f1_rf = f1_score(y_test, predictions_test)\n",
    "roc_rf = roc_auc_score(y_test, predictions_test)\n",
    "print(\"F1 Score: {}\".format(f1_rf))\n",
    "print(f\"ROC: {roc_rf}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_rf = confusion_matrix(y_test, predictions_test)\n",
    "sb.heatmap(confusion_matrix_rf, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning <a class=\"anchor\" id=\"parameter-tunning-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "\n",
    "    rf_grid_search = GridSearchCV(rf_classifier, scoring=\"roc_auc\", cv=5, param_grid={})\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "    print('Best score: {}'.format(rf_grid_search.best_score_))\n",
    "\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TRAIN\")\n",
    "    predictions_train = rf_grid_search.predict(X_train)\n",
    "    print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "    print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_rf = confusion_matrix(y_train, predictions_train)\n",
    "    sb.heatmap(confusion_matrix_rf, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TEST\")\n",
    "    predictions_test = rf_grid_search.predict(X_test)\n",
    "    rf_tun_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "    f1_rf_tun = f1_score(y_test, predictions_test)\n",
    "    roc_rf_tun = roc_auc_score(y_test, predictions_test)\n",
    "    print(\"F1 Score: {}\".format(f1_rf_tun))\n",
    "    print(f\"ROC: {roc_rf_tun}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_rf = confusion_matrix(y_test, predictions_test)\n",
    "    sb.heatmap(confusion_matrix_rf, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## XGBoost <a class=\"anchor\" id=\"xgboost\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "\n",
    "# Feature Selection\n",
    "xgb = RFECV(xgb, scoring='roc_auc')\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = xgb.predict(X_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print()\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_xgb = confusion_matrix(y_train, predictions_train)\n",
    "sb.heatmap(confusion_matrix_xgb, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = xgb.predict(X_test)\n",
    "xgb_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "f1_xgb = f1_score(y_test, predictions_test)\n",
    "roc_xgb = roc_auc_score(y_test, predictions_test)\n",
    "print(\"F1 Score: {}\".format(f1_xgb))\n",
    "print(f\"ROC: {roc_xgb}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_xgb = confusion_matrix(y_test, predictions_test)\n",
    "sb.heatmap(confusion_matrix_xgb, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning <a class=\"anchor\" id=\"parameter-tunning-8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    xgb_classifier = XGBClassifier()\n",
    "    \n",
    "    # Feature Selection\n",
    "    xgb_classifier = RFECV(xgb, scoring='roc_auc')\n",
    "\n",
    "    xgb_grid_search = GridSearchCV(xgb_classifier, scoring=\"roc_auc\", cv=5, param_grid={})\n",
    "    xgb_grid_search.fit(X_train, y_train)\n",
    "    print('Best score: {}'.format(xgb_grid_search.best_score_))\n",
    "\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TRAIN\")\n",
    "    predictions_train = xgb_grid_search.predict(X_train)\n",
    "    print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "    print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_xgb = confusion_matrix(y_train, predictions_train)\n",
    "    sb.heatmap(confusion_matrix_xgb, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TEST\")\n",
    "    predictions_test = xgb_grid_search.predict(X_test)\n",
    "    xgb_tun_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "    f1_xgb_tun = f1_score(y_test, predictions_test)\n",
    "    roc_xgb_tun = roc_auc_score(y_test, predictions_test)\n",
    "    print(\"F1 Score: {}\".format(f1_xgb_tun))\n",
    "    print(f\"ROC: {roc_xgb_tun}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_xgb = confusion_matrix(y_test, predictions_test)\n",
    "    sb.heatmap(confusion_matrix_xgb, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## MLP <a class=\"anchor\" id=\"mlp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(alpha=1, max_iter=1000)\n",
    "\n",
    "# Feature Selection\n",
    "# mlp = RFECV(mlp, scoring='roc_auc')\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = mlp.predict(X_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print()\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_mlp = confusion_matrix(y_train, predictions_train)\n",
    "sb.heatmap(confusion_matrix_mlp, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = mlp.predict(X_test)\n",
    "mlp_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "f1_mlp = f1_score(y_test, predictions_test)\n",
    "roc_mlp = roc_auc_score(y_test, predictions_test)\n",
    "print(\"F1 Score: {}\".format(f1_mlp))\n",
    "print(f\"ROC: {roc_mlp}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_mlp = confusion_matrix(y_test, predictions_test)\n",
    "sb.heatmap(confusion_matrix_mlp, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning <a class=\"anchor\" id=\"parameter-tunning-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    mlp_classifier = MLPClassifier(random_state=1, early_stopping=False)\n",
    "\n",
    "    mlp_grid_search = GridSearchCV(mlp_classifier, scoring=\"roc_auc\", cv=10, param_grid={})\n",
    "    mlp_grid_search.fit(X_train, y_train)\n",
    "    print('Best score: {}'.format(mlp_grid_search.best_score_))\n",
    "\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TRAIN\")\n",
    "    predictions_train = mlp_grid_search.predict(X_train)\n",
    "    print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "    print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_mlp = confusion_matrix(y_train, predictions_train)\n",
    "    sb.heatmap(confusion_matrix_mlp, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TEST\")\n",
    "    predictions_test = mlp_grid_search.predict(X_test) \n",
    "    mlp_tun_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "    f1_mlp_tun = f1_score(y_test, predictions_test)\n",
    "    roc_mlp_tun = roc_auc_score(y_test, predictions_test)\n",
    "    print(\"F1 Score: {}\".format(f1_mlp_tun))\n",
    "    print(f\"ROC: {roc_mlp_tun}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_mlp = confusion_matrix(y_test, predictions_test)\n",
    "    sb.heatmap(confusion_matrix_mlp, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## Ada Boost <a class=\"anchor\" id=\"ada-boost\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = AdaBoostClassifier()\n",
    "\n",
    "# Feature Selection\n",
    "boost = RFECV(boost, scoring='roc_auc')\n",
    "\n",
    "boost.fit(X_train, y_train)\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = boost.predict(X_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print()\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_boost = confusion_matrix(y_train, predictions_train)\n",
    "sb.heatmap(confusion_matrix_boost, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = boost.predict(X_test) \n",
    "boost_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "f1_boost = f1_score(y_test, predictions_test)\n",
    "roc_boost = roc_auc_score(y_test, predictions_test)\n",
    "print(\"F1 Score: {}\".format(f1_boost))\n",
    "print(f\"ROC: {roc_boost}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "sb.set(font_scale=1.0)\n",
    "ax = plt.subplot()\n",
    "confusion_matrix_boost = confusion_matrix(y_test, predictions_test)\n",
    "sb.heatmap(confusion_matrix_boost, annot=True, ax=ax, fmt=\"g\")\n",
    "ax.set_xlabel('Predicted Grades');\n",
    "ax.set_ylabel('Observed Grades');\n",
    "ax.set_title('Confusion Matrix');\n",
    "if show_confusion:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning <a class=\"anchor\" id=\"parameter-tunning-10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    ada_classifier = AdaBoostClassifier(random_state=0)\n",
    "\n",
    "    ada_grid_search = GridSearchCV(ada_classifier, scoring=\"roc_auc\", cv=5, param_grid={})\n",
    "    ada_grid_search.fit(X_train, y_train)\n",
    "    print('Best score: {}'.format(ada_grid_search.best_score_))\n",
    "\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TRAIN\")\n",
    "    predictions_train = ada_grid_search.predict(X_train)\n",
    "    print(\"F1 Score: {}\".format(f1_score(y_train, predictions_train)))\n",
    "    print(f\"ROC: {roc_auc_score(y_train, predictions_train)}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_ada = confusion_matrix(y_train, predictions_train)\n",
    "    sb.heatmap(confusion_matrix_ada, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "\n",
    "    print(53 * '=')\n",
    "    print(\"TEST\")\n",
    "    predictions_test = ada_grid_search.predict(X_test) \n",
    "    ada_tun_classification_report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "    f1_boost_tun = f1_score(y_test, predictions_test)\n",
    "    roc_boost_tun = roc_auc_score(y_test, predictions_test)\n",
    "    print(\"F1 Score: {}\".format(f1_boost_tun))\n",
    "    print(f\"ROC: {roc_boost_tun}\")\n",
    "    print(\"Classification Report: \")\n",
    "    print(classification_report(y_test, predictions_test, target_names=['not pay', 'pay']))\n",
    "    sb.set(font_scale=1.0)\n",
    "    ax = plt.subplot()\n",
    "    confusion_matrix_ada = confusion_matrix(y_test, predictions_test)\n",
    "    sb.heatmap(confusion_matrix_ada, annot=True, ax=ax, fmt=\"g\")\n",
    "    ax.set_xlabel('Predicted Grades');\n",
    "    ax.set_ylabel('Observed Grades');\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## Voting <a class=\"anchor\" id=\"voting\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote = VotingClassifier(\n",
    "#      estimators=[('dt', DecisionTreeClassifier()), ('svm', LinearSVC()), ('xgb', XGBClassifier())],\n",
    "#      voting='hard', weights=[1,1,1]\n",
    "# )\n",
    "\n",
    "# Feature Selection\n",
    "# classifier = RFECV(vote, scoring='roc_auc')\n",
    "\n",
    "# vote.fit(X_train, y_train)\n",
    "# vote_prediction = vote.predict(X_test)\n",
    "\n",
    "# vote_classification_report = classification_report(y_test, vote_prediction, output_dict=True)\n",
    "\n",
    "# print(f\"Classification report:\\n{classification_report(y_test, vote_prediction, labels=np.unique(y_train))}\\n\")\n",
    "\n",
    "# sb.set(font_scale=1.0)\n",
    "\n",
    "# ax = plt.subplot()\n",
    "\n",
    "# confusion_matrix_vote = confusion_matrix(y_test, vote_prediction)\n",
    "\n",
    "# sb.heatmap(confusion_matrix_vote, annot=True, ax=ax, fmt=\"g\")\n",
    "\n",
    "# ax.set_xlabel('Predicted Grades');\n",
    "# ax.set_ylabel('Observed Grades');\n",
    "# ax.set_title('Confusion Matrix');\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = go.Figure(data=[go.Table(header=dict(values=['Algorithm', 'Accuracy Normal', 'F1 Score Normal', 'ROC Score Normal']),\n",
    "                 cells=dict(values=[['DT', 'KNN', 'SVM', 'NN', 'LR', 'NB', 'RF', 'MLP', 'BOOST'], \n",
    "                                    [dtc_classification_report['accuracy'], knn_classification_report['accuracy'], svm_classification_report['accuracy'], nn_classification_report['accuracy'], lr_classification_report['accuracy'], nb_classification_report['accuracy'], rf_classification_report['accuracy'], mlp_classification_report['accuracy'], boost_classification_report['accuracy']], \n",
    "                                   [f1_dt, f1_knn, f1_svm, f1_nn, f1_lr, f1_nb, f1_rf, f1_mlp, f1_boost], [roc_dt, roc_knn, roc_svm, roc_nn, roc_lr, roc_nb, roc_rf, roc_mlp, roc_boost]]))\n",
    "                     ])\n",
    "\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_param_tunning:\n",
    "    table1 = go.Figure(data=[go.Table(header=dict(values=['Algorithm', 'Accuracy Normal', 'F1 Score Normal', 'ROC Score Normal']),\n",
    "                     cells=dict(values=[['DT', 'KNN', 'SVM', 'NN', 'LR', 'NB', 'RF', 'MLP', 'BOOST'], \n",
    "                                        [dtc_tun_classification_report['accuracy'], knn_tun_classification_report['accuracy'], 0, best_nn_classification_report['accuracy'], lr_tun_classification_report['accuracy'], nb_tun_classification_report['accuracy'], rf_tun_classification_report['accuracy'], mlp_tun_classification_report['accuracy'], boost_tun_classification_report['accuracy']], \n",
    "                                       [f1_dt, f1_knn, 0, f1_nn, f1_lr, f1_nb, f1_rf, f1_mlp, f1_boost], [roc_dt, roc_knn, 0, roc_nn, roc_lr, roc_nb, roc_rf, roc_mlp, roc_boost]]))\n",
    "                         ])\n",
    "\n",
    "    table1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_no_ids.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [back](#index)\n",
    "## Apply Model <a class=\"anchor\" id=\"apply-model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = test_data_no_ids.drop(columns=['status', 'loan_id'])\n",
    "\n",
    "pred_comp = lr_classifier.predict_proba(test_inputs)\n",
    "\n",
    "pred_comp = pd.DataFrame(pred_comp, columns=['col2', 'Predicted'])\n",
    "\n",
    "pred_comp.drop('col2', axis=1, inplace=True)\n",
    "all_ids_comp = pd.DataFrame(all_ids_comp, columns=['Id'])\n",
    "pred_comp['Predicted'] = [(1 - pred_comp['Predicted'][n]) for n in range(len(pred_comp))]\n",
    "results = pd.concat([all_ids_comp, pred_comp], axis=1)\n",
    "results = results.rename(columns={\"loan_id\":\"Id\"})\n",
    "results.to_csv('results.csv', index = False)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
